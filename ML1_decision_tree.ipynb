{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can use sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "from Function import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def read_csv(filename):\n",
    "    t = []\n",
    "    csv_file = open(filename,'r')\n",
    "    i =0\n",
    "    for row in csv.reader(csv_file):\n",
    "        # if (i > 2):\n",
    "        t.append(row)\n",
    "        # i+=1\n",
    "    # print (t)\n",
    "    t = np.array(t,dtype = np.float32)\n",
    "    return t\n",
    "\n",
    "def accF (x,y):\n",
    "    acc = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == y[i]:\n",
    "            acc +=1\n",
    "    acc = acc / len(x)\n",
    "    return acc \n",
    "\n",
    "\n",
    "##################################\n",
    "## your Feature extractor\n",
    "##################################\n",
    "\n",
    "def feature_ex(x):\n",
    "    t = []\n",
    "    x = np.array(x)\n",
    "    indexAx = 0\n",
    "    indexAy = 1\n",
    "    indexAz = 2\n",
    "    indexGx = 3\n",
    "    indexGy = 4\n",
    "    indexGz = 5\n",
    "    indexTotalAcc = 6\n",
    "    indexTotalGyro = 7\n",
    "    indexRoll = 8\n",
    "    indexPitch = 9\n",
    "    \n",
    "    totalAcc = getTotalAxes(x[indexAx],x[indexAy],x[indexAz])\n",
    "    totalGyro = getTotalAxes(x[indexGx],x[indexGy],x[indexGz])\n",
    "    roll = getRoll(x[indexAx],x[indexAz])\n",
    "    pitch = getPitch(x[indexAy],x[indexAz])\n",
    "\n",
    "    processedKoalaData = np.ones((10,40))\n",
    "\n",
    "    for i in range(6):\n",
    "        processedKoalaData[i] = copy.deepcopy(x[i])\n",
    "    processedKoalaData[6] = copy.deepcopy(totalAcc)\n",
    "    processedKoalaData[7] = copy.deepcopy(totalGyro)\n",
    "    processedKoalaData[8] = copy.deepcopy(roll)\n",
    "    processedKoalaData[9] = copy.deepcopy(pitch)\n",
    "\n",
    "\n",
    "\n",
    "    mean = getMean2D(processedKoalaData)\n",
    "\n",
    "    t.append(mean)\n",
    "\n",
    "\n",
    "    return t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = []\n",
    "label = []\n",
    "feature = []\n",
    "f = glob.glob(r'40_data/down'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([0])\n",
    "\n",
    "f = glob.glob(r'40_data/up'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([0])\n",
    "\n",
    "f = glob.glob(r'40_data/left'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([1])\n",
    "f = glob.glob(r'40_data/right'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([1])\n",
    "\n",
    "f = glob.glob(r'40_data/CW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([2])\n",
    "\n",
    "f = glob.glob(r'40_data/CCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([3])\n",
    "\n",
    "\n",
    "\n",
    "f = glob.glob(r'40_data/VLR'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([4])\n",
    "\n",
    "f = glob.glob(r'40_data/VRL'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([5])\n",
    "\n",
    "\n",
    "f = glob.glob(r'40_data/non'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([6])\n",
    "\n",
    "f = glob.glob(r'40_data/CRCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([7])\n",
    "\n",
    "f = glob.glob(r'40_data/CRCCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor shape is : (1096, 1, 10)\n",
      "sensor shape after is : (1096, 10)\n",
      "label shape is : (1096,)\n",
      "label is : [0 0 0 ... 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "sensor = np.array(sensor)\n",
    "print ('sensor shape is :',sensor.shape)\n",
    "\n",
    "feature_name = [ \"x[\"+str(i)+\"]\" for i in range((sensor.shape[1]*sensor.shape[2]))]\n",
    "sensor = np.reshape(sensor,(sensor.shape[0],sensor.shape[1]*sensor.shape[2]))\n",
    "label  = np.array(label)\n",
    "\n",
    "print ('sensor shape after is :',sensor.shape)\n",
    "print ('label shape is :',label.shape)\n",
    "print ('label is :',label)\n",
    "\n",
    "fea=[ 0 , 1,  2,  3,  4,  7,  9]\n",
    "sensor=sensor.take(fea,axis = 1)\n",
    "\n",
    "train_X, val_X, train_y, val_y =train_test_split(sensor, label, test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "sc.fit(train_X)\n",
    "train_X=sc.transform(train_X)\n",
    "sc.fit(val_X)\n",
    "val_X=sc.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=0)\n",
    "tree.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8727272727272727"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict(val_X)\n",
    "tree.score(val_X,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = glob.glob(r'testdata'+'/*.csv')\n",
    "test_data=[None]*99\n",
    "for i in range(len(f)):\n",
    "    test = read_csv(f[i])\n",
    "    if (len(test[0])) == 40:\n",
    "        test = feature_ex(test)\n",
    "        test_data[int(f[i][9:11])-1]=test\n",
    "        #test_data.append(test)\n",
    "test_data=np.array(test_data)\n",
    "test_data = np.reshape(test_data,(test_data.shape[0],test_data.shape[1]*test_data.shape[2]))\n",
    "print('test_data',test_data.shape)\n",
    "\n",
    "test_data=test_data.take(fea[:-1],axis = 1)\n",
    "#my_tree = build_tree(train_X)\n",
    "\n",
    "with open('predict_0319.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Id','Category'])\n",
    "    c=1\n",
    "    for row in test_data:\n",
    "        dic=classify(row, my_tree)\n",
    "        for label in dic.keys():\n",
    "            #print(int(label)) \n",
    "            writer.writerow([str(c).zfill(2)+\".csv\", int(label)])\n",
    "        c+=1\n",
    "      # print_leaf(classify(row, my_tree))))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
