{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can use sklearn\n",
    "#from sklearn.datasets import load_iris\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "from Function import *\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot  as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  # 準確率\n",
    "def read_csv(filename):\n",
    "    t = []\n",
    "    csv_file = open(filename,'r')\n",
    "    i =0\n",
    "    for row in csv.reader(csv_file):\n",
    "        # if (i > 2):\n",
    "        t.append(row)\n",
    "        # i+=1\n",
    "    # print (t)\n",
    "    t = np.array(t,dtype = np.float32)\n",
    "    return t\n",
    "\n",
    "def accF (x,y):\n",
    "    acc = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == y[i]:\n",
    "            acc +=1\n",
    "    acc = acc / len(x)\n",
    "    return acc \n",
    "\n",
    "\n",
    "##################################\n",
    "## your Feature extractor\n",
    "##################################\n",
    "\n",
    "def feature_ex(x):\n",
    "    t = []\n",
    "    x = np.array(x)\n",
    "    indexAx = 0\n",
    "    indexAy = 1\n",
    "    indexAz = 2\n",
    "    indexGx = 3\n",
    "    indexGy = 4\n",
    "    indexGz = 5\n",
    "    indexTotalAcc = 6\n",
    "    indexTotalGyro = 7\n",
    "    indexRoll = 8\n",
    "    indexPitch = 9\n",
    "    \n",
    "    totalAcc = getTotalAxes(x[indexAx],x[indexAy],x[indexAz])\n",
    "    totalGyro = getTotalAxes(x[indexGx],x[indexGy],x[indexGz])\n",
    "    roll = getRoll(x[indexAx],x[indexAz])\n",
    "    pitch = getPitch(x[indexAy],x[indexAz])\n",
    "\n",
    "    processedKoalaData = np.ones((10,40))\n",
    "\n",
    "    for i in range(6):\n",
    "        processedKoalaData[i] = copy.deepcopy(x[i])\n",
    "    processedKoalaData[6] = copy.deepcopy(totalAcc)\n",
    "    processedKoalaData[7] = copy.deepcopy(totalGyro)\n",
    "    processedKoalaData[8] = copy.deepcopy(roll)\n",
    "    processedKoalaData[9] = copy.deepcopy(pitch)\n",
    "\n",
    "\n",
    "\n",
    "    mean = getMean2D(processedKoalaData)\n",
    "\n",
    "    t.append(mean)\n",
    "\n",
    "\n",
    "    return t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = []\n",
    "label = []\n",
    "feature = []\n",
    "f = glob.glob(r'40_data/down'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([0])\n",
    "\n",
    "f = glob.glob(r'40_data/up'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([0])\n",
    "\n",
    "f = glob.glob(r'40_data/left'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([1])\n",
    "f = glob.glob(r'40_data/right'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([1])\n",
    "\n",
    "f = glob.glob(r'40_data/CW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([2])\n",
    "\n",
    "f = glob.glob(r'40_data/CCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([3])\n",
    "\n",
    "\n",
    "\n",
    "f = glob.glob(r'40_data/VLR'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([4])\n",
    "\n",
    "f = glob.glob(r'40_data/VRL'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([5])\n",
    "\n",
    "\n",
    "f = glob.glob(r'40_data/non'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([6])\n",
    "\n",
    "f = glob.glob(r'40_data/CRCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([7])\n",
    "\n",
    "f = glob.glob(r'40_data/CRCCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = np.array(sensor)\n",
    "print ('sensor shape is :',sensor.shape)\n",
    "\n",
    "feature_name = [ \"x[\"+str(i)+\"]\" for i in range((sensor.shape[1]*sensor.shape[2]))]\n",
    "sensor = np.reshape(sensor,(sensor.shape[0],sensor.shape[1]*sensor.shape[2]))\n",
    "label  = np.array(label)\n",
    "\n",
    "print ('sensor shape after is :',sensor.shape)\n",
    "print ('label shape is :',label.shape)\n",
    "print ('label is :',label)\n",
    "\n",
    "#fea=[ 0 , 1,  2,  3,  4,  7,  9]\n",
    "#sensor=sensor.take(fea,axis = 1)\n",
    "\n",
    "train_X, val_X, train_y, val_y =train_test_split(sensor, label, test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc=StandardScaler()\n",
    "#sc.fit(train_X)\n",
    "#train_X=sc.transform(train_X)\n",
    "#sc.fit(val_X)\n",
    "#val_X=sc.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster':'gbtree',\n",
    "    'objective':'multi:softmax',\n",
    "    'num_class':9,\n",
    "    'gamma':0.1,\n",
    "    'max_depth':11,\n",
    "    'lambda':2,\n",
    "    'subsample':0.7,\n",
    "    'colsample_bytree':0.7,\n",
    "    'min_child_weight':3,\n",
    "    'slient':1,\n",
    "    'eta':0.1,\n",
    "    'seed':1000,\n",
    "    'nthread':4,\n",
    "}\n",
    " \n",
    "plst = list(params.items())\n",
    "dtrain = xgb.DMatrix(train_X,train_y)\n",
    "num_rounds = 500\n",
    "# xgboost模型訓練\n",
    "model = xgb.train(plst,dtrain,num_rounds)\n",
    "dtest = xgb.DMatrix(val_X)\n",
    "y_pred = model.predict(dtest)\n",
    " \n",
    "# 計算準確率\n",
    "accuracy = accuracy_score(val_y,y_pred)\n",
    "print()\n",
    "print('accuarcy:%.2f%%'%(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data (105, 10)\n",
      "(105,)\n"
     ]
    }
   ],
   "source": [
    "f = glob.glob(r'testdata'+'/*.csv')\n",
    "test_data=[None]*105\n",
    "for i in range(len(f)):\n",
    "    test = read_csv(f[i])\n",
    "    s=f[i]\n",
    "    s=s.strip('testdata/')\n",
    "    s=s.strip('.csv')\n",
    "   # print(s)\n",
    "    if (len(test[0])) == 40:\n",
    "        test = feature_ex(test)\n",
    "        test_data[int(s)-1]=test\n",
    "test_data=np.array(test_data)\n",
    "test_data = np.reshape(test_data,(test_data.shape[0],test_data.shape[1]*test_data.shape[2]))\n",
    "#test_data=test_data.take(fea,axis = 1)\n",
    "print('test_data',test_data.shape)\n",
    "\n",
    "dtest = xgb.DMatrix(test_data)\n",
    "predict = model.predict(dtest)\n",
    "print(predict.shape)\n",
    "predict=predict.astype(int)\n",
    "#predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('predict_0319.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Id','Category'])\n",
    "    c=1\n",
    "    for row in predict:\n",
    "        #print([str(c).zfill(2)+\".csv\", row])\n",
    "        writer.writerow([str(c).zfill(2)+\".csv\", row])\n",
    "        c+=1\n",
    "      # print_leaf(classify(row, my_tree))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
