{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## you can use sklearn\n",
    "#from sklearn.datasets import load_iris\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "from Function import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import cross_validation, ensemble, preprocessing, metrics\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot  as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  # 準確率\n",
    "def read_csv(filename):\n",
    "    t = []\n",
    "    csv_file = open(filename,'r')\n",
    "    i =0\n",
    "    for row in csv.reader(csv_file):\n",
    "        # if (i > 2):\n",
    "        t.append(row)\n",
    "        # i+=1\n",
    "    # print (t)\n",
    "    t = np.array(t,dtype = np.float32)\n",
    "    return t\n",
    "\n",
    "def accF (x,y):\n",
    "    acc = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == y[i]:\n",
    "            acc +=1\n",
    "    acc = acc / len(x)\n",
    "    return acc \n",
    "\n",
    "\n",
    "##################################\n",
    "## your Feature extractor\n",
    "##################################\n",
    "\n",
    "def feature_ex(x):\n",
    "    t = []\n",
    "    x = np.array(x)\n",
    "    indexAx = 0\n",
    "    indexAy = 1\n",
    "    indexAz = 2\n",
    "    indexGx = 3\n",
    "    indexGy = 4\n",
    "    indexGz = 5\n",
    "    indexTotalAcc = 6\n",
    "    indexTotalGyro = 7\n",
    "    indexRoll = 8\n",
    "    indexPitch = 9\n",
    "    \n",
    "    totalAcc = getTotalAxes(x[indexAx],x[indexAy],x[indexAz])\n",
    "    totalGyro = getTotalAxes(x[indexGx],x[indexGy],x[indexGz])\n",
    "    roll = getRoll(x[indexAx],x[indexAz])\n",
    "    pitch = getPitch(x[indexAy],x[indexAz])\n",
    "\n",
    "    processedKoalaData = np.ones((10,40))\n",
    "\n",
    "    for i in range(6):\n",
    "        processedKoalaData[i] = copy.deepcopy(x[i])\n",
    "    processedKoalaData[6] = copy.deepcopy(totalAcc)\n",
    "    processedKoalaData[7] = copy.deepcopy(totalGyro)\n",
    "    processedKoalaData[8] = copy.deepcopy(roll)\n",
    "    processedKoalaData[9] = copy.deepcopy(pitch)\n",
    "\n",
    "\n",
    "\n",
    "    mean = getMean2D(processedKoalaData)\n",
    "\n",
    "    t.append(mean)\n",
    "\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "sensor = []\n",
    "label = []\n",
    "feature = []\n",
    "f = glob.glob(r'40_data/down'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([0])\n",
    "\n",
    "f = glob.glob(r'40_data/up'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([0])\n",
    "\n",
    "f = glob.glob(r'40_data/left'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([1])\n",
    "f = glob.glob(r'40_data/right'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([1])\n",
    "\n",
    "f = glob.glob(r'40_data/CW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([2])\n",
    "\n",
    "f = glob.glob(r'40_data/CCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([3])\n",
    "\n",
    "\n",
    "\n",
    "f = glob.glob(r'40_data/VLR'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([4])\n",
    "\n",
    "f = glob.glob(r'40_data/VRL'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([5])\n",
    "\n",
    "\n",
    "f = glob.glob(r'40_data/non'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([6])\n",
    "\n",
    "f = glob.glob(r'40_data/CRCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([7])\n",
    "\n",
    "f = glob.glob(r'40_data/CRCCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([8])\n",
    "sensor = np.array(sensor)\n",
    "#print ('sensor shape is :',sensor.shape)\n",
    "\n",
    "feature_name = [ \"x[\"+str(i)+\"]\" for i in range((sensor.shape[1]*sensor.shape[2]))]\n",
    "sensor = np.reshape(sensor,(sensor.shape[0],sensor.shape[1]*sensor.shape[2]))\n",
    "label  = np.array(label)\n",
    "\n",
    "#print ('sensor shape after is :',sensor.shape)\n",
    "#print ('label shape is :',label.shape)\n",
    "#print ('label is :',label)\n",
    "\n",
    "#fea=[ 0 , 1,  2,  3,  4,  7,  9]\n",
    "#sensor=sensor.take(fea,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "while(1):\n",
    "    train_X, val_X, train_Y, val_Y =train_test_split(sensor, label, test_size = 0.08)\n",
    "    f = glob.glob(r'testdata'+'/*.csv')\n",
    "    test_data=[None]*105\n",
    "    for i in range(len(f)):\n",
    "        test = read_csv(f[i])\n",
    "        s=f[i]\n",
    "        s=s.strip('testdata/')\n",
    "        s=s.strip('.csv')\n",
    "       # print(s)\n",
    "        if (len(test[0])) == 40:\n",
    "            test = feature_ex(test)\n",
    "            test_data[int(s)-1]=test\n",
    "    test_data=np.array(test_data)\n",
    "    test_data = np.reshape(test_data,(test_data.shape[0],test_data.shape[1]*test_data.shape[2]))\n",
    "    #test_data=test_data.take(fea,axis = 1)\n",
    "    #print('test_data',test_data.shape)\n",
    "    forest = ensemble.RandomForestClassifier(n_estimators = 100)\n",
    "    forest.fit(train_X, train_Y)\n",
    "    #print(boost_fit)\n",
    "    # 預測\n",
    "    val_pred = forest.predict(val_X)\n",
    "\n",
    "    # 績效\n",
    "\n",
    "    accuracy = metrics.accuracy_score(val_pred, val_Y)\n",
    "    if(accuracy>0.99):\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9562467250892299"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "forest = ensemble.RandomForestClassifier(n_estimators = 100)\n",
    "forest.fit(sensor, label)\n",
    "while(1):\n",
    "    scores_clf_svc_cv = cross_val_score(forest,sensor,label,cv=5)\n",
    "    #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_clf_svc_cv.mean(), scores_clf_svc_cv.std() * 2))\n",
    "    if(scores_clf_svc_cv.mean()>0.956):\n",
    "        break;\n",
    "scores_clf_svc_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = glob.glob(r'testdata'+'/*.csv')\n",
    "test_data=[None]*105\n",
    "for i in range(len(f)):\n",
    "    test = read_csv(f[i])\n",
    "    s=f[i]\n",
    "    s=s.strip('testdata/')\n",
    "    s=s.strip('.csv')\n",
    "    if (len(test[0])) == 40:\n",
    "        test = feature_ex(test)\n",
    "        test_data[int(s)-1]=test\n",
    "test_data=np.array(test_data)\n",
    "test_data = np.reshape(test_data,(test_data.shape[0],test_data.shape[1]*test_data.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=forest.predict(test_data)\n",
    "with open('predict_0330.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Id','Category'])\n",
    "    c=1\n",
    "    \n",
    "    for row in predict:\n",
    "        #print([str(c).zfill(2)+\".csv\", row])\n",
    "        writer.writerow([str(c).zfill(2)+\".csv\", row])\n",
    "        c+=1\n",
    "      # print_leaf(classify(row, my_tree))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train, test in kf.split(sensor, label):\n",
    "    train_data = np.array(sensor)[train]\n",
    "    test_data = np.array(y)[test]\n",
    "for rfc = RandomForestClassifier():\n",
    "    rfc.fit(train_data, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
