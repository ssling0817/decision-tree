{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can use sklearn\n",
    "#from sklearn.datasets import load_iris\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "from Function import *\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import manifold\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot  as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  # 準確率\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cross_validation, ensemble,metrics\n",
    "def read_csv(filename):\n",
    "    t = []\n",
    "    csv_file = open(filename,'r')\n",
    "    i =0\n",
    "    for row in csv.reader(csv_file):\n",
    "        # if (i > 2):\n",
    "        t.append(row)\n",
    "        # i+=1\n",
    "    # print (t)\n",
    "    t = np.array(t,dtype = np.float32)\n",
    "    return t\n",
    "\n",
    "def accF (x,y):\n",
    "    acc = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == y[i]:\n",
    "            acc +=1\n",
    "    acc = acc / len(x)\n",
    "    return acc \n",
    "\n",
    "\n",
    "##################################\n",
    "## your Feature extractor\n",
    "##################################\n",
    "'''\n",
    "def feature_ex(X):\n",
    "    X_tsne = manifold.TSNE().fit_transform(X)\n",
    "    #print(fit.components_)\n",
    "    return X_tsne\n",
    "'''\n",
    "def feature_ex(x):\n",
    "    t = []\n",
    "    x = np.array(x)\n",
    "    indexAx = 0\n",
    "    indexAy = 1\n",
    "    indexAz = 2\n",
    "    indexGx = 3\n",
    "    indexGy = 4\n",
    "    indexGz = 5\n",
    "    indexTotalAcc = 6\n",
    "    indexTotalGyro = 7\n",
    "    indexRoll = 8\n",
    "    indexPitch = 9\n",
    "    \n",
    "    totalAcc = getTotalAxes(x[indexAx],x[indexAy],x[indexAz])\n",
    "    totalGyro = getTotalAxes(x[indexGx],x[indexGy],x[indexGz])\n",
    "    roll = getRoll(x[indexAx],x[indexAz])\n",
    "    pitch = getPitch(x[indexAy],x[indexAz])\n",
    "\n",
    "    processedKoalaData = np.ones((10,40))\n",
    "\n",
    "    for i in range(6):\n",
    "        processedKoalaData[i] = copy.deepcopy(x[i])\n",
    "    processedKoalaData[6] = copy.deepcopy(totalAcc)\n",
    "    processedKoalaData[7] = copy.deepcopy(totalGyro)\n",
    "    processedKoalaData[8] = copy.deepcopy(roll)\n",
    "    processedKoalaData[9] = copy.deepcopy(pitch)\n",
    "\n",
    "\n",
    "\n",
    "    mean = getMean2D(processedKoalaData)\n",
    "\n",
    "    t.append(mean)\n",
    "\n",
    "\n",
    "    return t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = []\n",
    "label = []\n",
    "feature = []\n",
    "f = glob.glob(r'40_data/down'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([0])\n",
    "\n",
    "f = glob.glob(r'40_data/up'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([0])\n",
    "\n",
    "f = glob.glob(r'40_data/left'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([1])\n",
    "f = glob.glob(r'40_data/right'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([1])\n",
    "\n",
    "f = glob.glob(r'40_data/CW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([2])\n",
    "\n",
    "f = glob.glob(r'40_data/CCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([3])\n",
    "\n",
    "\n",
    "\n",
    "f = glob.glob(r'40_data/VLR'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([4])\n",
    "\n",
    "f = glob.glob(r'40_data/VRL'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([5])\n",
    "\n",
    "\n",
    "f = glob.glob(r'40_data/non'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([6])\n",
    "\n",
    "f = glob.glob(r'40_data/CRCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([7])\n",
    "\n",
    "f = glob.glob(r'40_data/CRCCW'+'/*.csv')\n",
    "for i in range(len(f)):\n",
    "    t = read_csv(f[i])\n",
    "    if (len(t[0])) == 40:\n",
    "        t = feature_ex(t)\n",
    "        sensor.append(t)\n",
    "        label.extend([8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = glob.glob(r'testdata'+'/*.csv')\n",
    "test_data=[None]*105\n",
    "for i in range(len(f)):\n",
    "    test = read_csv(f[i])\n",
    "    s=f[i]\n",
    "    s=s.strip('testdata/')\n",
    "    s=s.strip('.csv')\n",
    "       # print(s)\n",
    "    if (len(test[0])) == 40:\n",
    "        test = feature_ex(test)\n",
    "        test_data[int(s)-1]=test\n",
    "test_data=np.array(test_data)\n",
    "test_data = np.reshape(test_data,(test_data.shape[0],test_data.shape[1]*test_data.shape[2]))\n",
    "#test_data = manifold.TSNE().fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor shape is : (1096, 1, 10)\n",
      "sensor shape after is : (1096, 10)\n",
      "label is : [0 0 0 ... 8 8 8]\n",
      "test (105, 10)\n",
      "temp sensor (1201, 10)\n",
      "new sensor (1096, 2)\n",
      "new test (105, 2)\n"
     ]
    }
   ],
   "source": [
    "sensor = np.array(sensor)\n",
    "print ('sensor shape is :',sensor.shape)\n",
    "\n",
    "#feature_name = [ \"x[\"+str(i)+\"]\" for i in range((sensor.shape[1]*sensor.shape[2]))]\n",
    "sensor = np.reshape(sensor,(sensor.shape[0],sensor.shape[1]*sensor.shape[2]))\n",
    "label  = np.array(label)\n",
    "\n",
    "print ('sensor shape after is :',sensor.shape)\n",
    "#print ('label shape is :',label.shape)\n",
    "print ('label is :',label)\n",
    "\n",
    "#fea=[ 0 , 1,  2,  3,  4,  7,  9]\n",
    "#sensor=sensor.take(fea,axis = 1)\n",
    "print(\"test\",test_data.shape)\n",
    "sensor=np.append(sensor,test_data,axis=0)\n",
    "\n",
    "print(\"temp sensor\",sensor.shape)\n",
    "sensor = manifold.TSNE().fit_transform(sensor)\n",
    "sensor.shape\n",
    "test_data=sensor[1096:]\n",
    "sensor=sensor[0:1096]\n",
    "print(\"new sensor\",sensor.shape)\n",
    "print(\"new test\",test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while(1):\n",
    "    train_X, val_X, train_Y, val_Y =train_test_split(sensor, label, test_size = 0.1)\n",
    "    forest = ensemble.RandomForestClassifier(n_estimators = 1000)\n",
    "    forest.fit(train_X, train_Y)\n",
    "    val_pred = forest.predict(val_X)\n",
    "    accuracy = metrics.accuracy_score(val_pred, val_Y)\n",
    "    if(accuracy>0.93):\n",
    "        break;\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=forest.predict(test_data)\n",
    "with open('predict_0329.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Id','Category'])\n",
    "    c=1\n",
    "    for row in predict:\n",
    "        #print([str(c).zfill(2)+\".csv\", row])\n",
    "        writer.writerow([str(c).zfill(2)+\".csv\", row])\n",
    "        c+=1\n",
    "      # print_leaf(classify(row, my_tree))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sc=StandardScaler()\n",
    "train_X=sc.fit_transform(train_X)\n",
    "val_X=sc.fit_transform(val_X)\n",
    "test_data=sc.fit_transform(test_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMeans\n",
    "'''\n",
    "from sklearn.preprocessing import scale\n",
    "train_X=scale(train_X)\n",
    "val_X=scale(val_X)\n",
    "test_data=scale(test_data)\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "clf=KMeans(init='k-means++',n_clusters=7,random_state=6)\n",
    "clf.fit(train_X)\n",
    "'''\n",
    "'''\n",
    "# 載入 matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 設定圖形的大小\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "\n",
    "# 圖形標題\n",
    "fig.suptitle('Cluster Center Images', fontsize=14, fontweight='bold')\n",
    "for i in range(10):\n",
    "    # 在 2x5 的網格上繪製子圖形\n",
    "    ax = fig.add_subplot(2, 5, i + 1)\n",
    "    # 顯示圖片\n",
    "    ax.imshow(clf.cluster_centers_[i].reshape((5, 2)), cmap=plt.cm.binary)\n",
    "    # 將座標軸刻度關掉\n",
    "    plt.axis('off')\n",
    "\n",
    "# 顯示圖形\n",
    "plt.show()\n",
    "\n",
    "val_pred=clf.predict(val_X)\n",
    "error=0\n",
    "for i,v in enumerate(val_pred):\n",
    "    if v!=val_Y[i]:\n",
    "        error+=1\n",
    "print((float)(error)/val_pred.shape[0])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
